## Modelos HTR destacados (recetas médicas manuscritas en español)

Para reconocer texto manuscrito difícil (como recetas médicas en español, escritas a mano y sin estructura fija), existen varios modelos open source de **Handwritten Text Recognition (HTR)**. A continuación comparamos tres enfoques prominentes – **TrOCR**, **PyLaia** y **Kraken** – en términos de precisión, requisitos de datos, facilidad de adaptación (fine-tuning) y soporte comunitario.

### TrOCR (Transformer OCR de Microsoft)

TrOCR es un modelo HTR basado en Transformers (encoder-decoder) desarrollado por Microsoft ([microsoft/trocr-base-handwritten · Hugging Face](https://huggingface.co/microsoft/trocr-base-handwritten#:~:text=The%20TrOCR%20model%20is%20an,from%20the%20weights%20of%20RoBERTa)). Emplea un Vision Transformer como encoder de la imagen y un Transformer de lenguaje (inicializado con RoBERTa) como decoder ([microsoft/trocr-base-handwritten · Hugging Face](https://huggingface.co/microsoft/trocr-base-handwritten#:~:text=The%20TrOCR%20model%20is%20an,from%20the%20weights%20of%20RoBERTa)). Es capaz de reconocer texto a partir de imágenes de líneas de texto (generalmente una línea por vez) ([microsoft/trocr-base-handwritten · Hugging Face](https://huggingface.co/microsoft/trocr-base-handwritten#:~:text=Intended%20uses%20%26%20limitations)). 

- **Precisión:** TrOCR ha mostrado **precisión líder** en conjuntos de datos de escritura manual en inglés; por ejemplo, en el **dataset IAM** (textos manuscritos en inglés) alcanzó un **CER ~2.9%** (error por caracter) ([](https://www.iieta.org/download/file/fid/150823#:~:text=Li%20et%20al.%20,neural%20network%20without%20recurrent%20connections)), superando modelos previos. Sin embargo, aplicado directamente (sin re-entrenar) a otros manuscritos puede tener errores mayores; un usuario reportó ~15% CER con el modelo preentrenado de escritura a mano ([2023 review of tools for Handwritten Text Recognition HTR — OCR for handwriting : r/computervision](https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/#:~:text=%E2%80%A2)). Esto indica que se requiere ajuste para cada dominio para lograr baja tasa de error.
- **Datos y formato:** Para entrenar o ajustar TrOCR se necesitan pares de **imagen de texto** (preferiblemente a nivel de línea) con su transcripción. No exige un formato propietario específico; típicamente se prepara un conjunto de imágenes (por ejemplo, recortes de líneas de receta) y un archivo de etiquetas (JSONL, CSV o similares) que vincule cada imagen con el texto. Es crucial segmentar las líneas primero, pues TrOCR procesa **una línea a la vez** ([2023 review of tools for Handwritten Text Recognition HTR — OCR for handwriting : r/computervision](https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/#:~:text=bang%20for%20your%20buck)) – será necesario un paso de *detección/segmentación* de las líneas en la receta antes del reconocimiento.
- **Fine-tuning (personalización):** TrOCR permite fine-tuning sobre nuevos datos con relativa facilidad usando Hugging Face Transformers ([Qantev](https://www.qantev.com/post/spanish-trocr-leveraging-transfer-learning-for-language-adaptation#:~:text=English%20were%20all%20made%20available,6)). Se puede inicializar con un modelo pre-entrenado (ej. en inglés) y **re-entrenar con muestras de recetas españolas** para que aprenda el idioma y el estilo de escritura específicos. Microsoft liberó modelos base (por ejemplo, *trocr-base-handwritten*) con licencia MIT ([microsoft/trocr-base-handwritten · Hugging Face](https://huggingface.co/microsoft/trocr-base-handwritten#:~:text=arxiv%3A%202109)), que pueden adaptarse sin restricciones. El proceso de fine-tuning requiere GPU y suficientes datos anotados; estudios han utilizado millones de imágenes sintéticas para adaptar TrOCR a nuevos idiomas ([Qantev](https://www.qantev.com/post/spanish-trocr-leveraging-transfer-learning-for-language-adaptation#:~:text=English%20were%20all%20made%20available,6)), aunque para un caso específico (recetas médicas) bastaría con un conjunto más reducido pero representativo de la caligrafía de médicos.
- **Comunidad y soporte:** Al ser un modelo relativamente nuevo, TrOCR cuenta con **documentación** a través de Hugging Face (incluyendo tutoriales de uso) y un respaldo de la comunidad de OCR moderna. Existen implementaciones de ejemplo y foros activos discutiendo su entrenamiento ([Finetuning TrOCR on the IAM dataset - Hugging Face Forums](https://discuss.huggingface.co/t/finetuning-trocr-on-the-iam-dataset/21512#:~:text=Finetuning%20TrOCR%20on%20the%20IAM,there%20is%20no%20model%20saved)). Si bien no está especializado en español por defecto, hay esfuerzos de la comunidad en crear versiones en español (por ejemplo, Qantev liberó un TrOCR adaptado a español impreso) y guías para entrenamiento en otros idiomas. La disponibilidad del código abierto y la integración en librerías conocidas facilitan su adopción.

### PyLaia

PyLaia es un *toolkit* de código abierto enfocado en HTR, desarrollado en Python/PyTorch ([GitHub - jpuigcerver/PyLaia: A deep learning toolkit specialized for handwritten document analysis](https://github.com/jpuigcerver/PyLaia#:~:text=PyLaia)). Es sucesor de la biblioteca Laia, y utiliza una arquitectura clásica de **CNN + BLSTM con CTC** para reconocimiento de texto en imágenes de líneas manuscritas. PyLaia ha sido empleada en numerosos proyectos de investigación y competiciones de HTR, y es uno de los motores que integran plataformas como eScriptorium ([](https://arxiv.org/pdf/2404.18722#:~:text=These%20advances%20have%20contributed%20to,65f16e9ae0aa03690e9e9f80%202%20https%3A%2F%2Freadcoop.eu%2Ftranskribus%2F%203)). 

- **Precisión:** PyLaia ofrece **alto rendimiento** en reconocimiento manuscrito. De hecho, se le considera *estado del arte* en varios casos. Por ejemplo, es **popular en la comunidad ATR** por su **velocidad y exactitud** ([](https://arxiv.org/pdf/2404.18722#:~:text=TEKLIA%2C%20Paris%2C%20France%20Abstract,tuned)). En evaluaciones recientes, PyLaia logró ~8.9% CER (error de caracteres) y ~23.8% WER (error de palabras) en un conjunto de prueba difícil (escritura cursiva noruega) entrenando un modelo optimizado ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kraken%20expert%20120%20yes%200,12.62%2032.33)). Con datos abundantes, puede lograr incluso mejores resultados: en un dataset de oraciones en español (SPA-Sentences), un modelo basado en PyLaia obtuvo ~**2% CER** en el conjunto de prueba tras entrenamiento completo ([](https://riunet.upv.es/bitstream/handle/10251/198426/spa-sentences2022_VersionAutor.pdf?sequence=4&isAllowed=y#:~:text=Table%204%20Best%20CER%20on,6)), indicando su eficacia para español cuando se entrena apropiadamente.
- **Datos y formato:** PyLaia requiere normalmente un conjunto de **imágenes (de líneas de texto)** y sus transcripciones en texto plano. Suele utilizar formatos simples para el **ground truth**: por ejemplo, un fichero de texto que liste cada imagen junto a su transcripción (o directorios donde cada imagen tiene un `.txt` asociado). También soporta formatos estándares como XML de PAGE si se convierten las anotaciones. En la práctica, proyectos han publicado modelos PyLaia junto con *datasets* en formato compatible (p. ej., listas de pares imagen-texto o conversiones a JSONL) ([](https://arxiv.org/pdf/2404.18722#:~:text=without%20requiring%20any%20additional%20data,are%20released%20on%20Hugging%20Face1)). La preparación típica implica segmentar cada línea de la receta manuscrita en una imagen independiente y asegurar que el texto correspondiente (lo que el médico escribió en esa línea) esté en un archivo de etiquetas.
- **Fine-tuning:** PyLaia permite entrenar modelos desde cero o continuar entrenamientos existentes. Si se dispone de un modelo pre-entrenado (por ejemplo, en otro idioma o dominio), es posible cargarlo y realizar **fine-tuning con recetas médicas** propias, ajustando las últimas capas o usando un *learning rate* bajo para refinar. Teklia (mantenedores actuales) ha liberado **modelos pre-entrenados en 6 idiomas** ([](https://arxiv.org/pdf/2404.18722#:~:text=without%20requiring%20any%20additional%20data,are%20released%20on%20Hugging%20Face1)), lo que podría servir de punto de partida. La personalización requiere preparar los datos en el formato que PyLaia espera (por ejemplo, utilizando scripts de su repositorio para crear archivos de entrenamiento a partir de imágenes y transcripciones). Dado que PyLaia utiliza CTC, no requiere alineación estricta caracter a caracter, pero sí necesita que cada imagen de línea tenga su texto completo correcto.
- **Comunidad y documentación:** PyLaia cuenta con **buen soporte** por parte de la comunidad de investigación en HTR. Su código es abierto (licencia MIT) y está activo (mantenido por Teklia ([GitHub - jpuigcerver/PyLaia: A deep learning toolkit specialized for handwritten document analysis](https://github.com/jpuigcerver/PyLaia#:~:text=PyLaia%20is%20a%20device%20agnostic%2C,toolkit%20for%20handwritten%20document%20analysis))). Existe documentación en su Wiki y ejemplos de uso ([GitHub - jpuigcerver/PyLaia: A deep learning toolkit specialized for handwritten document analysis](https://github.com/jpuigcerver/PyLaia#:~:text=,examples)), así como publicaciones que lo utilizan (lo que ofrece material de referencia). Además, PyLaia ha sido integrado en plataformas sin código como Transkribus, eScriptorium o Arkindex ([](https://arxiv.org/pdf/2404.18722#:~:text=These%20advances%20have%20contributed%20to,65f16e9ae0aa03690e9e9f80%202%20https%3A%2F%2Freadcoop.eu%2Ftranskribus%2F%203)), lo que amplía su comunidad de usuarios. Si bien puede requerir más conocimiento técnico que soluciones “end-to-end” ya integradas, tiene la ventaja de ser **muy configurable** y de confianza comprobada en proyectos HTR académicos y comerciales.

### Kraken

Kraken es un motor OCR/HTR de código abierto (licencia Apache 2.0 ([kraken/docs/index.rst at main · mittagessen/kraken - GitHub](https://github.com/mittagessen/kraken/blob/master/docs/index.rst#:~:text=kraken%2Fdocs%2Findex,des%20Hautes%20%C3%89tudes%2C%20Universit%C3%A9))) derivado de Ocropus. Está diseñado para ser un sistema “**llave en mano**” que incluye tanto **segmentación de páginas** (detección de líneas) como reconocimiento de texto ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Asian%20languages,for%20recognition%20tasks%20in%20Kraken)). Kraken es especialmente usado en textos históricos y manuscritos difíciles, incluyendo escrituras cursivas (fue desarrollado con casos como árabe manuscrito en mente) ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kraken%20%5B13%5D%20is%20a%20turn,recognition%20of%20handwritten%20cursive%20text)). Utiliza redes neuronales (CNN+LSTM con CTC) entrenables mediante su herramienta de línea de comandos `ketos`. 

- **Precisión:** Kraken ha demostrado buen desempeño cuando se configura correctamente. Por defecto sus modelos base pueden ser simples (p. ej., 3 capas CNN + 3 LSTM) y requieren ajustes para logar alta precisión ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kraken%20basic%20%3A%20the%20model,by%20the%20authors%20of%20the)). En un estudio, un modelo “básico” de Kraken sin ajustes tuvo resultados pobres (CER >60% en pruebas) ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kaldi%20basic%2040%20no%205,11.49%2031.59)), pero tras optimizar (aumentar la resolución de entrada a 120px de alto, aplicar *data augmentation* y usar un modelo provisto por expertos) alcanzó ~**12.2% CER** y ~31% WER en el conjunto de prueba ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kaldi%20expert%2040%20no%204,56.10%2082.21)). Esto quedó cerca de otros motores HTR competitivos. En general, Kraken **funciona bien con entrenamiento personalizado**: usuarios reportan que entrenando con sus propios datos obtienen buena exactitud incluso en textos complicados (ej. manuscritos medievales) ([2023 review of tools for Handwritten Text Recognition HTR — OCR for handwriting : r/computervision](https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/#:~:text=YewTree1906)). Para recetas médicas en español, se esperaría que Kraken, entrenado con ejemplos representativos de la letra de médicos, pueda lograr niveles de error similares a otros modelos (posiblemente en el rango de 10–20% CER sin lenguaje post-corrección, mejorable con diccionarios o modelos de lenguaje).
- **Datos y formato:** Una fortaleza de Kraken es su soporte de **formatos estándar de anotación**. Recomienda usar **XML PAGE o ALTO** para los datos de entrenamiento ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=The%20training%20tools%20accept%20a,from%20the%20same%20datasets%20easily)), donde en cada archivo XML se definen las líneas de texto (coordenadas y transcripción) vinculadas a la imagen escaneada. Kraken puede ingerir directamente estos XML para entrenar tanto el segmentador como el reconocedor ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=Training%20data%20formats%C2%B6)) ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=ALTO%C2%B6)). Por ejemplo, desde eScriptorium se pueden exportar las transcripciones a ALTO o PAGE y luego usarlas con `ketos train` ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Kraken%20offers%20the%20ketos%20command,unzip%20them%20in%20a%20directory)). Alternativamente, Kraken permite un formato sencillo de **“manifest”**: un archivo de texto con rutas de imagen y su texto ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=Left%20and%20right%20padding%20around,lines)), o incluso pasar las imágenes y un archivo de transcripciones correlativo por línea en la línea de comando. En resumen, para preparar datos de recetas, se debería segmentar cada línea de la receta y almacenarla con su texto en alguno de estos formatos. Usar PAGE-XML/ALTO es **recomendable** porque son intercambiables con otras herramientas y evitan pérdidas de información ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=The%20training%20tools%20accept%20a,from%20the%20same%20datasets%20easily)), además de permitir reutilizar etiquetas existentes. 
- **Fine-tuning:** Kraken facilita el entrenamiento incremental. Es posible **continuar entrenando** un modelo existente con datos nuevos (por ejemplo, iniciar con un modelo genérico de escritura latina y refinarlo con nuestras recetas). Su herramienta `ketos` permite cargar modelos pre-entrenados como punto de partida. Existen modelos pre-entrenados de Kraken para distintos idiomas y épocas (p. ej., modelos comunitarios en repositorios como **OCR4all** o **HTR-United** para manuscritos históricos) que podrían emplearse. La personalización con Kraken suele implicar experimentar con hiperparámetros (tasa de aprendizaje, augmentations, etc.), ya que como vimos su desempeño mejora con ajustes expertos ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=the%20libraries%20was%20often%20very,In%20the%20case%20of%20Kraken)) ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=the%20results%20were%20very%20bad,recognition%2Ftree%2Fmaster%2Fdoc%2Farch)). No obstante, la curva de aprendizaje se compensa con la capacidad de entrenar **toda la tubería** (segmentación y reconocimiento) adaptada al estilo particular de los documentos.
- **Comunidad y documentación:** Kraken cuenta con una comunidad activa, sobre todo en el ámbito de humanidades digitales y bibliotecas. Dispone de **documentación oficial** en línea ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Kraken%2C%20in%20recent%20years%2C%20has,Kraken%20from%20its%20official%20documentation)) ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=transcribing%20connected%20scripts,Kraken%20from%20its%20official%20documentation)), incluyendo tutoriales paso a paso para entrenamiento ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Preparing%20Datasets%20for%20Training)). Herramientas como eScriptorium usan Kraken como backend, lo que refuerza su base de usuarios. En foros especializados, Kraken es considerado **“el mejor OCR open source para manuscritos”** en la actualidad junto a alternativas como Calamari ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Kraken%2C%20in%20recent%20years%2C%20has,Kraken%20from%20its%20official%20documentation)). Su desarrollador es accesible vía GitHub y la comunidad comparte modelos entrenados. En resumen, hay un **buen soporte comunitario**, aunque mayormente en inglés, y abundan recomendaciones prácticas (por ejemplo, usar Linux o WSL para Kraken, ya que no soporta Windows nativo ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Installing%20Kraken))). La documentación cubre desde instalación hasta formatos de salida, haciendo que incorporar Kraken en flujos personalizados sea viable.

## Herramientas y formatos para preparar datasets HTR

La preparación adecuada de los datos es **fundamental** para entrenar cualquier modelo HTR. En el caso de recetas médicas manuscritas (formato libre), normalmente se sigue este proceso: digitalizar o escanear las recetas, **segmentar** el texto en líneas (u otras unidades manejables) y asociar a cada imagen segmentada su transcripción textual correcta. A continuación, se describen formatos recomendados para representar estos pares imagen-texto y herramientas útiles para generarlos:

- **PAGE-XML:** Formato XML estándar (desarrollado por PRIMARESEARCH) que describe la estructura de la página y las transcripciones. En PAGE se pueden anotar regiones y líneas con sus coordenadas y el texto correspondiente. Es ampliamente usado en HTR (por ejemplo, Transkribus exporta en PAGE-XML) y es compatible con motores open source como Kraken y Calamari ([HTR-United](https://htr-united.github.io/#:~:text=HTR,Each%20dataset%20is%20carefully)). Un archivo PAGE-XML por página contendrá cada línea de la receta con su transcripción, permitiendo entrenar directamente modelos de reconocimiento a partir de allí. 
- **ALTO XML:** Otro estándar XML (“Analyzed Layout and Text Object”), utilizado frecuentemente por bibliotecas digitales. Similar a PAGE, ALTO incluye las coordenadas de líneas y el contenido de texto reconocido o transcrito. Kraken soporta ALTO versión 4.1+ para entrenamiento ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=ALTO%C2%B6)) ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=400%2020%22%3E%3C%21,%3CString%20ID%3D%22segment_K)). La ventaja de **XML (PAGE/ALTO)** es que integra la información de posicionamiento y texto, facilitando también entrenar la **segmentación de líneas** si se requiere. Estos formatos permiten conservar todos los detalles de layout de las recetas, aunque para usarlos se debe seguir sus esquemas (por suerte, herramientas de exportación normalmente lo manejan automáticamente).
- **JSONL / listas de pares imagen-texto:** Para propósitos de entrenamiento con librerías de *deep learning* (PyTorch, TensorFlow, etc.), a veces es más sencillo usar un formato ligero. **JSON Lines (JSONL)** consiste en un archivo donde cada línea es un objeto JSON independiente, típicamente con campos como `"image": "ruta/o/base64"`, `"text": "transcripción"`. Esto es útil si se va a crear un dataset con HuggingFace Datasets o escribir un script personalizado. De igual modo, un simple **archivo TXT/CSV** con `<ruta_imagen>\t<transcripción>` por línea puede servir (varias herramientas, incluido `ketos` de Kraken, aceptan un “manifest” similar) ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=Left%20and%20right%20padding%20around,lines)). Estos formatos no almacenan info de coordenadas (asumen que cada entrada ya es una línea recortada), pero son **fáciles de generar** y revisar manualmente. Para recetas, se puede optar por recortar cada línea de texto a una imagen separada (por ejemplo, `receta1_linea1.png`, `receta1_linea2.png`, etc.) y preparar un `.jsonl` donde cada entrada contenga el texto escrito en esa línea.

**Estructuración eficiente:** Es importante mantener la correspondencia exacta entre cada imagen y su texto. Se recomienda nombrar archivos con identificadores consistentes y evitar duplicados o desorden. Una práctica común es tener una carpeta con imágenes de entrenamiento y un archivo de índices (XML o JSONL) que las referencie. Si se usan formatos XML como PAGE, las imágenes pueden permanecer en una carpeta y múltiples XML (uno por página de receta) apuntarán a ellas. Esto permite escalabilidad y reutilización. Además, dividir el dataset en **train/validation/test** desde el inicio (manteniendo escritores únicos en cada partición si es relevante) ayudará a evaluar la precisión (CER/WER) de forma realista.

# Herramientas recomendadas:

Para obtener estos datos anotados existen varias herramientas open source útiles:

- **eScriptorium:** plataforma abierta para **segmentación y transcripción** de documentos manuscritos ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=In%20my%20previous%20posts%20for,for%20recognition%20tasks%20in%20Kraken)). Permite cargar imágenes de las recetas, delinear líneas (automáticamente con modelos de segmentación o manualmente) y transcribir el texto. Luego puede **exportar** los resultados en formatos ALTO o PAGE-XML fácilmente ([eScriptorium Tutorial (en) - lectaurep](https://lectaurep.hypotheses.org/documentation/escriptorium-tutorial-en#:~:text=eScriptorium%20Tutorial%20%28en%29%20,ALTO%2C%20%E2%80%9CPagexml%E2%80%9D%20for%20XML)). eScriptorium integra motores como Kraken y PyLaia para entrenar modelos dentro de la herramienta, lo que facilita un flujo completo (segmentar -> transcribir -> entrenar modelo -> reconocer nuevo documento) sin programar. Es muy adecuada para preparar datos de entrenamiento de manera visual e iterativa.
- **OCR4all:** suite open source orientada a documentos históricos pero aplicable a cualquier manuscrito. Ofrece una interfaz para segmentar páginas y corrección OCR. Internamente utiliza motores como Tesseract o Calamari, y soporta import/export de PAGE-XML y otros formatos. Usuarios han logrado buenos resultados entrenando modelos con OCR4all para manuscritos variados ([2023 review of tools for Handwritten Text Recognition HTR — OCR for handwriting : r/computervision](https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/#:~:text=YewTree1906)). Puede ser útil si se prefiere una solución integral de escritorio.
- **Transkribus (plataforma)**: Aunque no es open source, merece mención porque es muy usada en entornos de HTR. Sirve para transcribir documentos manualmente y **exportar** los datos en PAGE-XML. Si se cuenta con acceso, podría emplearse para generar el ground truth de recetas, que luego se entrena con PyLaia/Kraken localmente. Sin embargo, sus modelos HTR+ no son de código abierto, por lo que en este contexto solo se aprovecharía para la anotación manual.
- **Scripts personalizados:** Dado que las recetas médicas pueden requerir preprocesamiento (por ejemplo, mejorar el contraste, segmentar zonas de sello o firmas), a veces habrá que escribir código Python para preparar las imágenes. Librerías como OpenCV o PIL pueden recortar automáticamente líneas si la escritura está bien separada. También existen generadores sintéticos (como `trdg` o el generador VRD usado por Qantev ([Qantev](https://www.qantev.com/post/spanish-trocr-leveraging-transfer-learning-for-language-adaptation#:~:text=Synthetic%20VRD%20dataset%20in%20Spanish%3A))) para crear datos *falsos* y aumentar el entrenamiento, aunque en el caso de recetas la variabilidad de la caligrafía individual es difícil de simular. En cualquier caso, una vez se tengan pares imagen-texto, formatearlos a JSONL o XML podrá hacerse con un script.



# Fuentes:

Los datos y comparativas presentados provienen de estudios y documentaciones recientes sobre HTR, incluyendo evaluaciones de TrOCR ([](https://www.iieta.org/download/file/fid/150823#:~:text=Li%20et%20al.%20,neural%20network%20without%20recurrent%20connections)), discusiones de usuarios sobre su desempeño ([2023 review of tools for Handwritten Text Recognition HTR — OCR for handwriting : r/computervision](https://www.reddit.com/r/computervision/comments/15er2y7/2023_review_of_tools_for_handwritten_text/#:~:text=%E2%80%A2)), análisis comparativos de PyLaia y Kraken ([](https://storage.teklia.com/teklia-public-website/documents/DAS2022_HUMU_XwbTkyc.pdf#:~:text=Kaldi%20expert%2040%20no%204,56.10%2082.21)), publicaciones sobre mejoras en PyLaia ([](https://arxiv.org/pdf/2404.18722#:~:text=TEKLIA%2C%20Paris%2C%20France%20Abstract,tuned)), y guías de herramientas como Kraken ([Training — kraken  documentation](https://kraken.re/3.0/ketos.html#:~:text=The%20training%20tools%20accept%20a,from%20the%20same%20datasets%20easily)) ([Train Your Own OCR/HTR Models with Kraken, part 1 – The Digital Orientalist](https://digitalorientalist.com/2023/09/26/train-your-own-ocr-htr-models-with-kraken-part-1/#:~:text=Kraken%20offers%20the%20ketos%20command,unzip%20them%20in%20a%20directory)), entre otros. Cada modelo y formato mencionado es de código abierto o estándar de la industria, idóneo para construir una solución a medida para **recetas médicas manuscritas**.